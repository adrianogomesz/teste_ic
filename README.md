**Teste TÃ©cnico â€“ Pipeline de Dados ANS**

Autor: Adriano Gomes
Stack: Python, Pandas, Requests, BeautifulSoup
Objetivo: Construir um pipeline completo de ingestÃ£o, tratamento, enriquecimento e agregaÃ§Ã£o de dados pÃºblicos da ANS, com foco em robustez, clareza tÃ©cnica e decisÃµes justificadas.


**VisÃ£o Geral do Projeto**

Este projeto implementa um pipeline ETL (Extract, Transform, Load) a partir de dados pÃºblicos da ANS (AgÃªncia Nacional de SaÃºde Suplementar), cobrindo:

- Download automatizado dos dados trimestrais de despesas

- Tratamento de dados inconsistentes (padrÃ£o comum em dados governamentais)

- Enriquecimento com dados cadastrais das operadoras (CADOP)

- AgregaÃ§Ã£o final por operadora, UF, ano e trimestre

- GeraÃ§Ã£o de arquivos CSV finais e compactaÃ§Ã£o para entrega

Os dados nÃ£o sÃ£o versionados no repositÃ³rio. Todo o processo Ã© reprodutÃ­vel via execuÃ§Ã£o do pipeline.


ğŸ“ Estrutura do Projeto
Teste_AdrianoGomes/
â”œâ”€â”€ api_ans/
â”‚   â”œâ”€â”€ main.py         # OrquestraÃ§Ã£o do pipeline
â”‚   â”œâ”€â”€ scraper.py      # NavegaÃ§Ã£o e descoberta de URLs
â”‚   â”œâ”€â”€ downloader.py   # Download e extraÃ§Ã£o de arquivos
â”‚   â”œâ”€â”€ http_client.py  # ComunicaÃ§Ã£o HTTP isolada
â”‚   â”œâ”€â”€ transformer.py  # Limpeza, enriquecimento e agregaÃ§Ãµes
â”‚   â”œâ”€â”€ utils.py        # FunÃ§Ãµes utilitÃ¡rias (ex: formataÃ§Ã£o BRL)
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # Dados brutos (ignorado no Git)
â”‚   â””â”€â”€ processed/      # Dados processados (ignorado no Git)
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore


**Arquitetura do Pipeline (ETL)**
Extract:

- NavegaÃ§Ã£o automÃ¡tica no repositÃ³rio FTP da ANS

- LocalizaÃ§Ã£o da pasta DemonstraÃ§Ãµes ContÃ¡beis

- IdentificaÃ§Ã£o dos 3 trimestres mais recentes

- Download e extraÃ§Ã£o de arquivos .zip

Transform:

- Leitura defensiva dos CSVs trimestrais

- NormalizaÃ§Ã£o de nomes de colunas

- ConversÃ£o segura de valores monetÃ¡rios

- Enriquecimento com dados cadastrais (CADOP)

- InclusÃ£o de UF e Modalidade

- AgregaÃ§Ãµes analÃ­ticas

Load:

- ExportaÃ§Ã£o de CSVs finais

- CodificaÃ§Ã£o compatÃ­vel com Excel

- CompactaÃ§Ã£o dos arquivos de entrega


**Tradeoffs TÃ©cnicos**
**Scraping vs API REST**

Apesar do PDF mencionar â€œAPI RESTâ€, os dados da ANS sÃ£o disponibilizados via repositÃ³rio FTP pÃºblico, sem endpoints REST clÃ¡ssicos.

Para contornar isso, utilizei requests + BeautifulSoup para navegar e descobrir recursos dinamicamente.

Justificativa:

- NÃ£o hÃ¡ documentaÃ§Ã£o de endpoints REST formais

- Estrutura FTP Ã© estÃ¡vel e pÃºblica

- Evita hardcode de URLs

SeparaÃ§Ã£o de Responsabilidades (Arquitetura)

O cÃ³digo foi dividido em mÃ³dulos com responsabilidades claras:

- scraper.py â†’ Descoberta de URLs

- downloader.py â†’ Download e extraÃ§Ã£o

- transformer.py â†’ Regras de negÃ³cio e dados

- utils.py â†’ FunÃ§Ãµes puras reutilizÃ¡veis

- main.py â†’ OrquestraÃ§Ã£o do fluxo

Justificativa:

- CÃ³digo mais legÃ­vel

- Facilita testes unitÃ¡rios

- Facilita manutenÃ§Ã£o e evoluÃ§Ã£o


**Leitura Defensiva de CSVs Governamentais**

Dados pÃºblicos frequentemente apresentam encoding inconsistentes, colunas com nomes variados, valores numÃ©ricos como strings, dados faltates ou invÃ¡lidos. 
Para contornar isso, utilizei encoding explicito na leitura (latin1), normalizei nomes de colunas, utilizei validaÃ§Ãµes explicitas de schema, erros tratados por arquivo sem quebrar o pipeline inteiro.


**FormataÃ§Ã£o MonetÃ¡ria (BRL)**
Formatar valores como string vs manter valores numÃ©ricos

Os valores foram mantidos como float durante todo o processamento, a formataÃ§Ã£o para BRL foi aplicada apenas na etapa final de exportaÃ§Ã£o.

Justificativa:

- Evita erros em cÃ¡lculos

- Facilita uso futuro em banco de dados ou APIs

- MantÃ©m precisÃ£o durante agregaÃ§Ãµes


**EstratÃ©gia de AgregaÃ§Ã£o**

AgregaÃ§Ã£o realizada por:

- CNPJ

- RazaoSocial

- UF

- Ano

- Trimestre

MÃ©tricas calculadas:

- DespesaTotal

- DespesaMediaTrimestre

- Resultados ordenados por DespesaTotal (decrescente).

Essa estrutura atende tanto anÃ¡lises exploratÃ³rias quanto uso posterior em banco ou API.


**Dados NÃ£o Versionados**

Os diretÃ³rios data/raw e data/processed sÃ£o ignorados no Git.

Justificativa:

- Evita versionamento de dados grandes

- RepositÃ³rio mais limpo

- Pipeline totalmente reprodutÃ­vel

Para gerar os dados:

python -m api_ans.main


**Arquivos Gerados**

despesas_consolidadas.csv

despesas_agregadas.csv

Teste_Adriano_Gomes.zip

Todos gerados automaticamente pelo pipeline.


**Como reproduzir?**

Crie um ambiente virtual:

windows: 
1. python -m venv venv

2. .\venv\Scripts\activate

linux/mac:
1. python3 -m venv venv

2. source venv/bin/activate


Instale dependÃªncias:

pip install -r requirements.txt


Execute:

python -m api_ans.main


**ConsideraÃ§Ãµes Finais:**

Este projeto foi desenvolvido com foco em:

- Robustez frente a dados reais

- Clareza arquitetural

- Justificativa consciente de trade-offs

- Boas prÃ¡ticas de versionamento e organizaÃ§Ã£o


**O pipeline foi pensado para ser facilmente extensÃ­vel para:**

- PersistÃªncia em banco de dados

- ExposiÃ§Ã£o via API

- IntegraÃ§Ã£o com ferramentas analÃ­ticas